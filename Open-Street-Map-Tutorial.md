_**This Tutorial is under construction.**_

This Tutorial can be used without having your own hadoop cluster at hand. For testing the examples on your own cluster please read section [[Adaptation|Open Street Map Tutorial##Adaptation]].

# Goals


# Prerequisites
* basic knowledge of [Apache Hive](http://hive.apache.org/)

# Installation
Let's get started:

1. Download [Cloudera Quickstart VM](http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cloudera_quickstart_vm.html)
2. Start Cloudera VM.
3. Open a terminal and clone the Schedoscope git repository:

    `[cloudera@quickstart ~]$ git clone https://github.com/ottogroup/schedoscope.git`
4. Change directory to `schedoscope` and build the project:

    `[cloudera@quickstart schedoscope]$ mvn install`

# Execution

1. Change directory to `~/schedoscope/schedoscope-tutorial` and execute the tutorial:

    `[cloudera@quickstart schedoscope-tutorial]$ mvn exec:java`
2. The Schedoscope Shell opens in the terminal. Find the full [[command reference|Command Reference]] in the Schedoscope wiki.
3. Type  `materialize -v schedoscope.example.osm.datamart/ShopProfiles`

    and see how all data is digested which is needed in order to provide the requested view of shop profiles.
4. Type  `actions`
    and see which kind of transformations are running.
5. Type  `views`
    and see which views are already materialized with current data.
6. Have a look in the browser at the application manager of your Hadoop Cluster  <http://localhost:8088/cluster>
    and see the MR-Jobs running on the cluster.
9. Type `shutdown` if you want to stop Schedoscope.

# Exploration
7. Open a new terminal. Use the hive CLI to see the data generated by triggering the ETL with Schedoscope
    1. list the databases
    2. list the tables of a database
    3. list the columns of a table
    4. list the first 10 entries of a table
    5. perform an analysis on the data provided
7. Type  `invalidate -v schedoscope.example.osm.datahub/Restaurants` in the schedoscope shell.

    This is how to manually tell Schedoscope that this view shall be recalculated.
8. Type  `materialize -v schedoscope.example.osm.datamart/ShopProfiles`

    Type  `views` to see that only `demo_schedoscope_example_osm_datahub.restaurants` and its depending view `demo_schedoscope_example_osm_datamart.ShopProfiles` are recalculated. Schedoscope knows that the other views' data still is up-to-date.
8. Switch to hive CLI and compare column `created_at` of `restaurants` and `shops`. As you can see table `restaurants` has been written again during recalculation. Table `shops` has not been touched.
9. Type `shutdown` if you want to stop Schedoscope.


# Adaptation
Thus the example code is running now in Cloudera Quickstart VM. Try get it running with your own hadoop cluster now.
 
Simply install Schedoscope on your own machine (see [[Installation|Open Street Map Tutorial##Installation]] step 3 and 4). Then change the [[configuration settings|Configuring Schedoscope]] in `schedoscope-tutorial/src/main/resources/schedoscope.conf` as follows:

**VM's schedoscope.conf:**

    schedoscope {
      app {
         environment = "demo"
      }

    transformations = {
      hive : {
              libDirectory = "/home/cloudera/schedoscope-tutorial/target/hive-libraries"
              concurrency = 2                # number of parallel actors to execute hive transformations
        }
      }
    }

**your new schedoscope.conf:**

    schedoscope {
      app {
         environment = "test"
      }

      metastore {
        metastoreUri = "your/hive/metastore/uri"
        jdbcUrl = "your/hive/jdbc/uri"
      }

      kerberos {
        principal = "your/kerberos/principal"   # if needed
      }
      
      transformations = {
      	hive : {
		    libDirectory = "/home/cloudera/schedoscope-tutorial/target/hive-libraries"
		    url = ${schedoscope.metastore.jdbcUrl}
        }
      }
    }
The [[default configuration settings|Configuring Schedoscope]] are derived from `schedoscope-core/src/main/resources/reference.conf`. They are overwritten by the settings you define in your project's `schedoscope.conf`.

Change directory to `schedoscope/schedoscope-tutorial` and execute the tutorial using your own hadoop cluster:

    [cloudera@quickstart schedoscope-tutorial]$ mvn exec:java


# Extension
Now it's time to design your own views and their dependencies.

## Preparation
1. You need a Scala IDE, e.g. [Scala IDE for Eclipse](http://scala-ide.org/download/sdk.html)
2. Import the maven project schedoscope-tutorial
3. Set scala compiler on version 2.10 in the project's properties

## Development
Use other Open Street Map TSV-files provided by schedoscope-tutorial-osm-data:

* `ways.txt`  (way is a sequence of 2-2000 nodes)

        id BIGINT
        version INT
        user_id INT
        tstamp TIMESTAMP
        changeset_id BIGINT

* `way_nodes.txt`  (mapping of nodes on ways)

        way_id BIGINT
        node_id BIGINT
        sequence_id INT

* `way_tags.txt`  (tags for ways)

        way_id BIGINT
        k STRING
        v STRING

These files can be read in from classpath. Have a look at the tutorial class `schedoscope.example.osm.stage.Nodes` .

The custom [Test Framework](Test Framework) allows **test-driven development** for schedoscope.

1. Create a stub for your view.
2. Implement your testclass.
3. Implement your view while testing its behaviour using the provided test framework.

Based on your new views `ways`, `way_tags` and `way_nodes` you can implement a view `schedoscope.example.osm.processed.Ways` that comprises all information about ways according to view `schedoscope.example.osm.processed.Nodes`. Therefore, use UDF `collect` to create a map of tags as in `Nodes` and an array of node_id which are part of this way.

## Deployment
Restart Schedoscope (your project).


# Hints

